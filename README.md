# ğŸš€ Mimo Language Model

Mimo est un **modÃ¨le de langage open-source** fine-tunÃ© pour exceller Ã  la fois en **gÃ©nÃ©ration de code** et en **conversations naturelles**.  
GrÃ¢ce Ã  son architecture basÃ©e sur **DeepSeek-Qwen-1.5B** et son fine-tuning spÃ©cialisÃ© (LoRA + datasets code & conversation), il atteint des performances supÃ©rieures aux modÃ¨les conventionnels sur des tÃ¢ches pratiques.

![Mimo](assets/mimo.png)

---

## âœ¨ Points forts de Mimo

- ğŸ”§ **OptimisÃ© pour le code** : gÃ©nÃ©ration fiable de scripts Python, JS, etc.  
- ğŸ’¬ **Excellente conversation** : rÃ©ponses naturelles et contextualisÃ©es.  
- âš¡ **CompatibilitÃ© multiplateforme** : fonctionne sur Mac, PC et VSCode.  
- ğŸ“¦ **PrÃªt pour la quantification** (GGUF) â†’ utilisable avec LM Studio ou Ollama.  

---

## ğŸ“¦ Installation

Clonez le dÃ©pÃ´t et installez les dÃ©pendances :

```bash
git clone https://github.com/votre-utilisateur/mimo-llm.git
cd mimo-llm
pip install -r requirements.txt
```

âš ï¸ Assurez-vous dâ€™avoir `git-lfs` installÃ© pour gÃ©rer les poids du modÃ¨le.

---

## ğŸ”‘ Configuration

Avant toute utilisation, configurez votre **Hugging Face Token** :

```bash
export HF_TOKEN="votre_token_hugging_face"
```

---

## ğŸ‹ï¸ Fine-tuning

Lancez le fine-tuning avec :

```bash
python fine_tune_mimo.py
```

- Utilise vos donnÃ©es perso (`mohamed.jsonl`)  
- Combine un sous-ensemble du dataset public `mosaicml/instruct-v3`  
- Sauvegarde les poids et tokenizer dans `./Mimo`  

---

## ğŸ§‘â€ğŸ’» Exemples dâ€™utilisation

### GÃ©nÃ©ration de code

```python
prompt = "Ã‰cris une fonction Python pour trier une liste."
inputs = mimo_tokenizer(prompt, return_tensors="pt")
outputs = mimo_model.generate(**inputs, max_new_tokens=100)
print(mimo_tokenizer.decode(outputs[0], skip_special_tokens=True))
```

### Conversation

```python
prompt = "Quelle est la meilleure faÃ§on d'apprendre une nouvelle langue ?"
inputs = mimo_tokenizer(prompt, return_tensors="pt")
outputs = mimo_model.generate(**inputs, max_new_tokens=150)
print(mimo_tokenizer.decode(outputs[0], skip_special_tokens=True))
```

---

## ğŸ“Š Performances comparatives

| ModÃ¨le                          | Code (Python) | Conversation | MÃ©moire requise |
|---------------------------------|---------------|--------------|-----------------|
| GPT-Neo 1.3B                    | â­â­            | â­â­           | ~12 Go          |
| DeepSeek-Qwen-1.5B (base)       | â­â­â­           | â­â­â­          | ~10 Go          |
| **Mimo-1.5B (fine-tuned)**      | â­â­â­â­          | â­â­â­â­         | ~8 Go (quantisÃ©) |

â¡ï¸ **Mimo surpasse la version de base** sur les benchmarks internes (code + QA).

---

## ğŸ“‚ Structure du dÃ©pÃ´t

```
Mimo/
â”œâ”€â”€ README.md
â”œâ”€â”€ assets/mimo.png
â”œâ”€â”€ mohamed.jsonl
â”œâ”€â”€ fine_tune_mimo.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ .gitignore
```

---

## ğŸ› ï¸ IntÃ©gration dans VSCode

1. Clonez le dÃ©pÃ´t :  
   ```bash
   git clone https://github.com/votre-utilisateur/mimo-llm.git
   cd mimo-llm
   ```
2. Installez les dÃ©pendances :  
   ```bash
   pip install -r requirements.txt
   ```
3. ExÃ©cutez soit :  
   - `fine_tune_mimo.py` â†’ pour lâ€™entraÃ®nement  
   - un script dâ€™infÃ©rence personnalisÃ©  

âš¡ Vous pouvez aussi utiliser Mimo dans **LM Studio** en important la version quantisÃ©e GGUF.

---

## ğŸ“§ Auteur

- **Nom** : ABDESSEMED Mohamed  
- **Entreprise** : Eurocybersecurite  
- **Contact** : mohamed.abdessemed@eurocybersecurite.fr  
